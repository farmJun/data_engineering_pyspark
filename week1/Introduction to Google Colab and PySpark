# Introduction to Google Colab and PySpark by 박준영

- 5. Jupyter Notebook Basics
    - 1. Code cells
        
        ![스크린샷 2024-07-05 오후 11.03.10.png](Introduction%20to%20Google%20Colab%20and%20PySpark%20by%20%E1%84%87%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%AE%E1%86%AB%2096440b8e0cf046bc94297180e54ffec7/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-05_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_11.03.10.png)
        
        간단한 파이썬의 곱셉 연산이다.
        
        파이썬에서 사칙연산은 외에도 덧셈은 ‘+’, 뺄셈은 ‘-’, 곱셉은 ’*’ 나눗셈은 ‘/’로 사용 가능하다.
        
        ---
        
        ![스크린샷 2024-07-05 오후 11.06.26.png](Introduction%20to%20Google%20Colab%20and%20PySpark%20by%20%E1%84%87%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%AE%E1%86%AB%2096440b8e0cf046bc94297180e54ffec7/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-05_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_11.06.26.png)
        
        파이썬의 collections 모듈의 Counter 클래스를 import하는 코드이다.
        
        파이썬만 설치되어 있으면, 별도의 패키지 설치 없이 Counter 클래스를 import하여 사용할 수 있다.
        
        이 Counter 클래스는 데이터의 개수를 측정할 때 아주 유용하다.
        
        ![스크린샷 2024-07-05 오후 11.09.52.png](Introduction%20to%20Google%20Colab%20and%20PySpark%20by%20%E1%84%87%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%AE%E1%86%AB%2096440b8e0cf046bc94297180e54ffec7/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-05_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_11.09.52.png)
        
        Counter 생성자는 여러 형태의 데이터를 인자로 받는다. 중복된 데이터가 저장된 배열을 인자로 넘기면, 각 원소가 배열에 몇 번 포함되어있는지 저장된 Counter 객체를 얻을 수 있다.
        
        위는 Counter 생성자에 준영 2번, 지우 1번, 수지 1번이 포함되어 있어서 결과로 위와 같은 Counter 객체를 얻는다. 
        
        ---
        
        ![스크린샷 2024-07-05 오후 11.15.35.png](Introduction%20to%20Google%20Colab%20and%20PySpark%20by%20%E1%84%87%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%AE%E1%86%AB%2096440b8e0cf046bc94297180e54ffec7/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-05_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_11.15.35.png)
        
        파이썬의 출력문이다. print()의 인자로 큰 따옴표, 작은 따옴표 아무거나 사용가능하다.
        
    - 2. Text cells
        
        ![스크린샷 2024-07-05 오후 11.20.51.png](Introduction%20to%20Google%20Colab%20and%20PySpark%20by%20%E1%84%87%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%AE%E1%86%AB%2096440b8e0cf046bc94297180e54ffec7/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-05_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_11.20.51.png)
        
        텍스트 셀을 수정하려면, 특정  셀로 이동하여 ENTER 키를 누르거나 마우스로 더블 클릭한다.
        
        그러면 위와 같이 텍스트 셀에 텍스트를 추가할 수 있고, 오른쪽에서 미리 볼 수 있다.
        
        수정 사항 저장은 ESC 키를 누르거나, 다른 셀을 클릭하면 된다.
        
    - 3. Access to the shell
        
        ![스크린샷 2024-07-05 오후 11.23.10.png](Introduction%20to%20Google%20Colab%20and%20PySpark%20by%20%E1%84%87%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%AE%E1%86%AB%2096440b8e0cf046bc94297180e54ffec7/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-05_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_11.23.10.png)
        
        ls는 list의 약자로, 현재 directory에 존재하는 파일들을 리스트로 출력한다.
        
        ---
        
        ![스크린샷 2024-07-05 오후 11.28.11.png](Introduction%20to%20Google%20Colab%20and%20PySpark%20by%20%E1%84%87%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%AE%E1%86%AB%2096440b8e0cf046bc94297180e54ffec7/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-05_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_11.28.11.png)
        
        pwd는 print working directory의 약자로. 현재 작업 중인 directory 이름을 출력한다.
        
        위에 예시는 현재 작업 중인 directory는 /content이고, 이 directory에 sample_data를 포함한 총 5개의 파일이 존재한다는 뜻이다.
        
    - 4. Installing Spark
        - !apt-get install openjdk-8-jdk-headless -qq > /dev/null
            - OpenJDK 8의 headless 버전을 설치
            - headless 버전은 GUI 관련 라이브러리 없이 Java 설치
            - -qq : 설치 과정에서 출력되는 메시지를 최소화
            - > dev/null : 출력되는 메시지가 화면에 표시되지 않도록 버림.
        - !wget -q [http://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz](http://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz)
            - Apache Spark 3.5.1의 바이너리 파일을 다운로드
            - wget : 지정된 URL에서 파일을 다운로드
            - -q : 다운로드 진행 상황을 출력하지 않음.
        - tar xf spark-3.5.1-bin-hadoop3.tgz
            - 다운로드한 tar.gz 파일을 압축 해제
            - tar sf : tar 파일을 추출, x는 extract, f는 file을 의미
        - !pip install -q findspark
            - 파이썬 패키지 findspark를 설치하는 명령어
            - pip install : 지정된 파이썬 패키지를 설치
            - -q : 다운로드 진행 상황을 출력하지 않음.
            - findspark : 파이썬과 Spark 사이의 통합을 쉽게 해주는 패키지
        
        ![스크린샷 2024-07-05 오후 11.43.24.png](Introduction%20to%20Google%20Colab%20and%20PySpark%20by%20%E1%84%87%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%AE%E1%86%AB%2096440b8e0cf046bc94297180e54ffec7/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-05_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_11.43.24.png)
        
        기존 노트북에서 실행하면, 이미 파일이 존재한다고 나와서 복제 후 새 노트북에서 재실행 
        
        ![스크린샷 2024-07-05 오후 11.50.12.png](Introduction%20to%20Google%20Colab%20and%20PySpark%20by%20%E1%84%87%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%AE%E1%86%AB%2096440b8e0cf046bc94297180e54ffec7/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-05_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_11.50.12.png)
        
        대략 13분 정도 소요됨. 
        
        ---
        
        환경 변수 설정
        
        ![스크린샷 2024-07-05 오후 11.57.10.png](Introduction%20to%20Google%20Colab%20and%20PySpark%20by%20%E1%84%87%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%AE%E1%86%AB%2096440b8e0cf046bc94297180e54ffec7/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-05_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_11.57.10.png)
        
        - import os
            - 파이썬의 os 모듈을 import함.
            - os 모듈은 운영 체제와 상호작용하는 기능을 제공하는 표준 라이브러리이다.
            - 이 모듈을 통해 환경 변수 설정, 파일 시스템 경로를 다룰 수 있다.
        - os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64”
            - JAVA_HOME이란 환경 변수 설정
            - Java의 설치 경로를 os.envirion을 사용해 환경 변수로 설치하여 Spark가 Java의 설치 경로를 알 수 있다.
        - os.environ["SPARK_HOME"] = "/content/spark-3.5.1-bin-hadoop3”
            - SPARK_HOME이란 환경 변수 설정
            - Spark와 관련된 라이브러리 및 실행 파일들의 위치를 알 수 있다.
            
            ![스크린샷 2024-07-06 오전 12.02.38.png](Introduction%20to%20Google%20Colab%20and%20PySpark%20by%20%E1%84%87%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%AE%E1%86%AB%2096440b8e0cf046bc94297180e54ffec7/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-06_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_12.02.38.png)
            
        - import findspark
            - findspark 모듈을 import
            - findspark를 통해 spark의 설치 경로를 찾고 설정할 수 있다.
        - findspark.init()
            - findspark를 초기화하낟.
            - Spark의 설치 경로를 환경 변수에서 읽어들여, 파이썬에서 Spark를 사용할 수 있도록 설정.
            - 위에서 설정한 SPARK_HOME 환경 변수로 Spark 라이브러리를 찾음.
        - from pyspark.sql import SparkSession
            - prspark.sql 모듈의 SparkSession을 import
            - pyspark는 파이썬에서 Apache Spark를 사용할 수 있게하는 라이브러리
            - SparkSession은 Spark의 기본 진입점, Spark SQL을 사용하여 데이터 프레임을 생성하고 작업 수행 가능
        - spark = SparkSession.builder.master("local[*]").getOrCreate()
            - Spark Session을 생성
            - SparkSession.builder : Spark Session을 구성하는 빌더 객체 생성
            - .master(”local[*]”) : Spark를 로컬 모드로 실행하며, 모든 CPU 코어를 사용하도록 설정
            - “local[*]” : 시스템의 모든 코어를 사용한다는 뜻.
            - .getOrCreate() : 기존의 Spark Session이 존재하면 그것을 반환하고, 없다면 새로 생성
        - spark.conf.set("spark.sql.repl.eagerEval.enabled", True)
            - Spark Session의 설정을 변경
            - spark.conf.set() : Spark의 설정을 변경하는 메서드
            - “spark.sql.repl.eagerEval.enabled”, True : Spark 데이터 프레임을 출력할 때, 테이블 형식으로 출력되도록  설정.
        - spark
            - SparkSession 객체를 반환 및 출력
        
